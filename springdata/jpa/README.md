  
# Spring Data Jpa What is Jpa? 
Java Persistence API is a collection of classes and methods to persistently store the vast amounts of data into a database.    
    
JPA is an open source API, therefore various enterprise vendors such as Oracle, Redhat, Eclipse, etc. provide new products by adding the JPA persistence flavor in them. Some of these products include: Hibernate, Eclipselink, Toplink, Spring Data JPA, etc.    
  
# Spring Data JPA Basics
The DAO layer usually consists of a lot of boilerplate code that can and should be simplified. The advantages of such a simplification are many: a decrease in the number of artifacts that we need to define and maintain, consistency of data access patterns and consistency of configuration.    
  
Spring Data takes this simplification one step forward and makes it possible to remove the DAO implementations entirely. The interface of the DAO is now the only artifact that we need to explicitly define.  
  
In order to start leveraging the Spring Data programming model with JPA, a DAO interface needs to extend the JPA specific Repository interface (JpaRepository). This will enable Spring Data to find this interface and automatically create an implementation for it.  
  
By extending the interface we get the most relevant CRUD methods for standard data access available in a standard DAO.  
  
# Overview of Spring Data JPA Features  
- Sophisticated support to build repositories based on Spring and JPA.  
- Support for Querydsl predicates and thus type-safe JPA queries.  
- Transparent auditing of domain class.  
- Pagination support, dynamic query execution, ability to integrate custom data access code.  
- Validation of @Query annotated queries at bootstrap time.  
- Support for XML based entity mapping.  
- JavaConfig based repository configuration by introducing @EnableJpaRepositories.  
  
To configure JPA with Spring, we need to use the @Transactional annotation, combined with a transaction manager and the @EnableTransactionManagement annotation.  The only difference with Spring Boot is, however, that it automatically sets the @EnableTransactionManagement annotation and creates a PlatformTransactionManager for you - with its JDBC auto-configurations.  
  
Before getting started with Spring Data, let's cover some JPA basics, such us annotations used to define the entities and the different relationships between entities.  
    
# Entities  
We use the following annotations to define an entity:    
- `@Entity`: basic annotation to tell JPA this class is an entity. JPA needs to be aware of the entity.    
  - The entity name defaults to the name of the class. We can change its name using the name element: `@Entity(name="student")`.    
- `@Id`: this annotation defines the primary key. We can generate the identifiers in different ways which are specified by the @GeneratedValue annotation. We can choose from four id generation strategies with the strategy element. The value can be AUTO, TABLE, SEQUENCE, or IDENTITY.    
  - AUTO: it picks the strategy that is preferred by the used database platform. The preferred strategies are IDENTITY for MySQL, SQLite and MsSQL and SEQUENCE for Oracle and PostgreSQL. This strategy provides full portability.    
  - TABLE: it uses a separate table for ID generation.    
  - SEQUENCE: it uses a database sequence for ID generation. This strategy does currently not provide full portability.    
  - IDENTITY: it uses special identity columns in the database that generate a value on insertion of a row. This strategy does currently not provide full portability and is supported by the following platforms:    
    - MySQL/SQLite/SQL Anywhere (AUTO_INCREMENT).    
    - PostgreSQL (SERIAL).    
- `@Table`: it is used when the name of the table and the name of the entity are not the same. We can even set the schema: `@Table(name="STUDENT", schema="SCHOOL")`.    
- `@Column`: we can use this annotation to mention the details of a column in the table. The properties available are:    
  - columnDefinition: the SQL fragment that is used when generating the DDL for the column.    
  - insertable: whether the column is included in SQL INSERT statements generated by the persistence provider. Default true.    
  - length: the column length. (Applies only if a string-valued column is used). Default 255.    
  - name: the name of the column.    
  - nullable: whether the database column is nullable. Default true.    
  - precision: the precision for a decimal (exact numeric) column. (Applies only if a decimal column is used.) Value must be set by developer if used when generating the DDL for the column. Default 0.    
  - scale: the scale for a decimal (exact numeric) column. (Applies only if a decimal column is used.) Default 0.    
  - table: the name of the table that contains the column. If absent the column is assumed to be in the primary table.    
  - unique: whether the column is a unique key. This constraint applies in addition to any constraint entailed by primary key mapping and to constraints specified at the table level. Default false.    
  - updatable: whether the column is included in SQL UPDATE statements generated by the persistence provider. Default true.    
- `@Transient`: this annotation is used when we want a field not to be persisted. For instance, we can calculate the age of a person from the date of birth. We want the age to be part of the entity, but not to have that information int the database.    
  - There is a difference between this annotation and the transient keyword. When a field is annotated with @Transient, it won't be mapped in the database, but it'll be included in the serialization of the object. If we use the transient keyword instead of the annotation, the field won't be included neither in the database nor in the serialization of the object.    
  - The value of the transient field is calculated in the get method.     
- `@Temporal`: it is used to save temporal values in our table. We can define 3 different types:    
  - TemporalType.TIMESTAMP: equivalent to java.sql.Timestamp.    
  - TemporalType.DATE: equivalent to java.sql.Date.    
  - TemporalType.TIME: equivalent to java.sql.Time.    
- `@Enumerated`: we can use this annotation to specify whether the enum should be persisted by name or by ordinal. Default ordinal. We don't have to use this annotation at all if we're gonna persist a field as ordinal.    
  - EnumType.STRING    
  - EnumType.ORDINAL    
    
# Relationships  
To explain the relationship between entities we're gonna work with the following model:  
- Student has 1 and only 1 Address. One-to-One relationship.  
- Studen has 1 and only 1 Gender. One-to-One relationship.  
- Student can take 1 to many Courses. One-to-Many relationship.  
- Course can be taken by 0 to many Students. One-to-Many relationship.  
- Course can be run by 1 and only 1 Teacher. One-to-One relationship.  
- Teacher can give 0 to many Courses. One-to-Many relationship.  
    
We can achieve the Many-to-One relationship if we see the One-to-Many from the other side. For instance, multiple courses can be run by 1 teacher.  
    
## One-to-One relationship  
The annotation used to map this relationship is @OneToOne with the help of the @JoinColumn in case we want to modify some properties of that field. The @OneToOne annotation has the following properties:  
- cascade: the operations that must be cascaded to the target of the association. By default, no operations are cascaded. Potential values:  
  - CascadeType.ALL  
  - CascadeType.PERSIST  
  - CascadeType.MERGE  
  - CascadeType.REMOVE  
  - CascadeType.REFRESH  
  - CascadeType.DETACH  
- fetch: whether the association should be lazily loaded or must be eagerly fetched. Potential values:  
  - FetchType.LAZY  
  - FetchType.EAGER (default value)  
- optional: whether the association is optional. Default true.  
- mappedBy: the field that owns the relationship. This element is only specified on the inverse (non-owning or child) side of the association. The entity which owns the relationship is the one which has the FK.  
- orphanRemoval: whether to apply the remove operation to entities that have been removed from the relationship and to cascade the remove operation to those entities. Default false.  
- targetEntity: the entity class that is the target of the association. Defaults to the type of the field or property that stores the association.  
  
This relationship can be implemented in different ways.  
1. The first and the simplest way to do it is in a unidirectional way. To do that, the parent entity must have a reference to the child entity but the child entity can not have any reference to the parent entity. When the parent entity is persisted, the child entity is persisted too, but there is no way of traveling from the child entity to the parent entity. In the next example, the load of the address is done lazily.  

```java
@Entity
@Data
public class Student {
    @Id
    @GeneratedValue(strategy = GenerationType.AUTO)
    private Long id;
    private String firstName;
    private String lastName;
    //One-to-One relationship
    @OneToOne(fetch = FetchType.LAZY, cascade = CascadeType.ALL, optional = false)
    @JoinColumn(name = "address")
    private Address address;
}
  
@Entity
@Data
public class Address {
    @Id
    @GeneratedValue(strategy = GenerationType.AUTO)
    private Long id;
    @Column(length = 100)
    private String street;
    @Column(length = 50)
    private String city;
    @Column(length = 2)
    private String state;
    @Column(length = 5)
    private String zipCode;
    @Column(length = 15)
    private String country;
}
```
  
2. The second way to implement this relationship is in a bidirectional way. In this case, both the parent and the child have a specific link to the other side, so we can travel from one to another without using specific queries. In this type of relationship, when the parent is loaded we can specify whether it must be retrieved in a LAZY or EAGER way, but when working with the child, it's gonna be retrieved always in a EAGER way.  
    
```java
Student.java
@OneToOne(fetch = FetchType.LAZY, cascade = CascadeType.ALL, optional = false)
@JoinColumn(name = "address")
private Address address;
  
Address.java
@OneToOne(mappedBy = "address")
private Student student;
```

In the student table there is 1 PK and 1 FK to address (2 keys). The load of the student can be done both in LAZY mode (fetch = FetchType.LAZY) and in EAGER mode (fetch = FetchType.EAGER). However, the load of the address entity is always done in EAGER mode.  
  
The same could be done but having the FK in the address table instead of the student one.  
  
3. The third way to implement this relationship is in a bidirectional way sharing primary key. Since there can be just 1 address per student, there is no need of having different PK and PK in address, we could use the same value as PK/FK, which is the PK of the student. Since the FK is in the address table (address is the parent and child is the ), there is no way of lazy loading the student entity.  

```java
Student.java
@Entity(name = "students")
@Data
public class Student {
    @Id
    @GeneratedValue(strategy = GenerationType.AUTO)
    private Long id;
    private String firstName;
    private String lastName;
    //One-to-One relationship
    @OneToOne(cascade = CascadeType.ALL, mappedBy = "student", optional = false)
    private Address address;
}

Address.java
@Entity(name = "addresses")
@Data
public class Address {
    @Id
    private Long id;
    @Column(length = 100)
    private String street;
    @Column(length = 50)
    private String city;
    @Column(length = 2)
    private String state;
    @Column(length = 5)
    private String zipCode;
    @Column(length = 15)
    private String country;
    //One-to-One relationship
    @OneToOne(fetch = FetchType.LAZY)
    @MapsId
    private Student student;
}
```

## One-to-Many (and Many-to-One) relationship  
We're gonna build this example with teacher and course. One teacher can teach 0 or more courses (several courses can be taught by 1 teacher), which means that the FK of the teacher is in the course table. The annotation used to map this relationship is @OneToMany. The @OneToMany annotation has the following properties:  
- cascade: the operations that must be cascaded to the target of the association. By default, no operations are cascaded. Potential values:  
  - CascadeType.ALL  
  - CascadeType.PERSIST  
  - CascadeType.MERGE  
  - CascadeType.REMOVE  
  - CascadeType.REFRESH  
  - CascadeType.DETACH  
- fetch: whether the association should be lazily loaded or must be eagerly fetched. Potential values:  
  - FetchType.LAZY  
  - FetchType.EAGER (default value)  
- mappedBy: the field that owns the relationship. This element is only specified on the inverse (non-owning or child) side of the association. The entity which owns the relationship is the one which has the FK.  
- orphanRemoval: whether to apply the remove operation to entities that have been removed from the relationship and to cascade the remove operation to those entities. Default false.  
- targetEntity: the entity class that is the target of the association. Defaults to the type of the field or property that stores the association.  
  
1. The first way to do it is in a unidirectional way, even though there are two implementations of a unidirectional way. In this case, we'll have a list of the multiple entities into the unique entity. In this first method a new intermediary table will be created with the PK of teacher and student. This way, when we create a teacher and link to the teacher 3 courses, if we save the teacher three things will happen: 1- The teacher will be inserted into the teacher table. 2- The course will be inserted into the course table. 3- The relationships between teacher and course will be inserted into the table teacher_course. There is no FK neither in the teacher table nor in the course table. This is the same way to get a many to many relationship, but we're using it to implement a one-to-many relationship.  
  
The @OneToMany association is by definition a parent (non-owning) association, even if it’s a unidirectional or a bidirectional one. Only the parent side of an association makes sense to cascade its entity state transitions to children. When persisting the Teacher entity, the cascade will propagate the persist operation to the underlying Course children as well. Upon removing a Course from the courses collection, the association row is deleted from the link table, and the orphanRemoval attribute will trigger a Course removal as well.  
  
The unidirectional associations are not very efficient when it comes to removing child entities. On the other hand, a bidirectional  @OneToMany  association is much more efficient because the child entity controls the association.  

```java
@Data
@Entity
public class Teacher {
    @Id
    @GeneratedValue(strategy = GenerationType.AUTO)
    private Long id;
    @Column(length = 100)
    private String firstName;
    @Column(length = 100)
    private String lastName;
    @OneToMany(targetEntity=Course.class, cascade = CascadeType.ALL, fetch = FetchType.LAZY, orphanRemoval = true)
    List<Course> course;
}

@Data
@Entity
public class Course {
    @Id
    @GeneratedValue(strategy = GenerationType.AUTO)
    private Long id;
    @Column(length = 100)
    private String title;
}`
```
  
In this case, the fetch EAGER will trigger a query over the teacher_course table with the id of the teacher to retrieve the list of courses.  
  
2. The other way to achieve a unidirectional relationship is by using the FK association. In this case, since a teacher can teach lots of courses, the course will have a FK to the teacher table. With this technique we're assuring that one course can be run by one and just one teacher. The only difference between this way and the previous one is the use of the annotation @JoinColumn.  

```java
@OneToMany(targetEntity=Course.class, cascade = CascadeType.ALL, fetch = FetchType.EAGER, orphanRemoval = true)
@JoinColumn(name="teacher")
List<Course> course;
```
  
Now, when the teacher is inserted, what the implementation of JPA does is to insert the teacher, to insert the courses and then to update the courses with the id of the teacher. There is no table in the middle. In this case, the fetch EAGER will trigger a query over the course table with the id of the teacher to retrieve the list of courses.  
  
3. The next way to achieve this relationship is the bidirectional relationship. Now, the teacher will be aware of the courses and the course will be aware of the teacher. This relationship requires @OneToMany on one side and @ManyToOne on the other side. Although the domain model exposes two sides to navigate this association, behind the scenes, the relational database has only one foreign key for this relationship.  
  
Every bidirectional association must have one owning side only, the other one being referred to as the inverse (or the mappedBy) side. The mappedBy element defines a bidirectional relationship. This attribute allows you to refer the associated entities from both sides. The best way to map a @OneToMany association is to rely on the @ManyToOne side to propagate all entity state changes.  
  
In this method, what Hibernate will do is first to insert the teacher and then to insert the course with the teacher information. Unlike the unidirectional @OneToMany, the bidirectional association is much more efficient when managing the collection persistence state (for instance there is no need of update sentence and every teacher removal only requires a single update of the course table in which the foreign key column is set to NULL). Since the course has a teacher field, there is no need of updating it after the insertion, but we need to assign the teacher to the course before storing the course. Both sides of the relationship can be loaded in LAZY or EAGER way.  
  
The bidirectional @OneToMany association is the best way to map a one-to-many database relationship when we really need the collection on the parent side of the association. It’s good practice to override equals and hashCode for the child entity in a bidirectional association.  

```java
@Entity
public class Teacher {
    @Id
    @GeneratedValue(strategy = GenerationType.AUTO)
    private Long id;
    @Column(length = 100)
    private String firstName;
    @Column(length = 100)
    private String lastName;
    @OneToMany(targetEntity=Course.class, cascade = CascadeType.ALL, fetch = FetchType.LAZY, mappedBy = "teacher")
    List<Course> course;
}

@Data
@Entity
public class Course {
    @Id
    @GeneratedValue(strategy = GenerationType.AUTO)
    private Long id;
    @Column(length = 100)
    private String title;
    @ManyToOne(targetEntity=Teacher.class, fetch = FetchType.EAGER)
    @JoinColumn(name="teacher")
    private Teacher teacher;
}
```

### Best practices for Many-To-One and One-To-Many relationships  
We can follow as a basic guide the next best practices for these two relationships:  
1. Don’t use unidirectional one-to-many associations: both bidirectional one-to-many and many-to-one association mappings are fine. But we should avoid unidirectional one-to-many associations in your domain model. Otherwise, Hibernate might create unexpected tables and execute more SQL statements than you expected.  
2. Avoid the mapping of huge to-many associations: mapped to-many associations are useful, especially when we want to join entities in a JPQL query. But Hibernate loads all associated entities when it initializes the association. That can take several seconds or even minutes when Hibernate has to fetch several thousand entities. So, better use a unidirectional many-to-one association. When we need to read the associated entities, it’s better to use a JPQL query with pagination. That allows to fetch a number of entities that we can handle in your business logic.  
3. Think twice before using CascadeType.Remove: cascade remove is another feature that works well on small to-many associations. Using it for one-to-many or many-to-one associations is not as dangerous as it is for many-to-many relationships. But it’s very inefficient when it needs to remove a huge number of entities.  
4. Use orphanRemoval when modeling parent-child associations: the orphanRemoval feature can make it very comfortable to remove a child entity. You can use it for parent-child relationships in which a child entity can’t exist without its parent entity (for instance, purchase and purchase items).  
5. Implement helper methods to update bi-directional associations: bidirectional associations are comfortable to use in queries and to navigate relationships in your domain model. But they require special attention when we update them. When we add an entity to or remove it from an association, we need to perform the operation on both ends. Let's see the following example:  

```java
@Entity
public class Purchase {
   ...
    public void addItem(Item item) {
        this.items.add(item);
        item.setOrder(this);
    }
}
```
 
6. Define FetchType.LAZY for @ManyToOne association: the JPA specification defines FetchType.EAGER as the default for to-one relationships. It tells Hibernate to initialize the association, when it loads the entity. That is not a big deal, if we just load one entity. It requires just 1 additional query if we use JPQL query and Hibernate creates an INNER JOIN when you use the EntityManager.find method. But that dramatically changes when you select multiple Item entities.  
  
## Many-to-Many relationship  
The last type of relationship is the many to many one, where 1 instance of A is linked to 0-1 or many instances of B, and 1 instance of B is linked to 0-1 or many instances of A. We're gonna explain this relationship with the entities Course and Student, where a course can have 1 or more students and 1 student can attend 1 or many courses. The many-to-many relationship is always achieved by creating an intermediary table (called join table) with the id of both instances as PK. In this case, the table will have as PK the FK of the course and the FK of the student. To manage this, the annotation @JoinTable is used (we'll see later how to personalize the intermediary table).  
  
The annotation used to map this relationship is @ManyToMany. This annotation has the following properties:  
- cascade: the operations that must be cascaded to the target of the association. By default, no operations are cascaded. Potential values:  
  - CascadeType.ALL  
  - CascadeType.PERSIST  
  - CascadeType.MERGE  
  - CascadeType.REMOVE  
  - CascadeType.REFRESH  
  - CascadeType.DETACH  
- fetch: whether the association should be lazily loaded or must be eagerly fetched. Potential values:  
  - FetchType.LAZY (default value)  
  - FetchType.EAGER  
- mappedBy: the field that owns the relationship. This element is only specified on the inverse (non-owning or child) side of the association.  
- targetEntity: the entity class that is the target of the association. Defaults to the type of the field or property that stores the association.  
  
The properties of the @JoinTable annotation are:  
- name: name of the table. The default value will be composed by putting together both tables of the relationship with a "_".  
- catalog: the catalog of the table  
- foreignKey: used to specify or control the generation of a foreign key constraint for the columns corresponding to the joinColumns element when table generation is in effect.  
- indexes: indexes for the table. Used in schema generation to specify creation of an index.  
- inverseForeignKey: used to specify or control the generation of a foreign key constraint for the columns corresponding to the inverseJoinColumns element when table generation is in effect.  
- inverseJoinColumns: the foreign key columns of the join table which reference the primary table of the entity that does not own the association. In other words, the PK of the target table or child of the association.  
- joinColumns: the foreign key columns of the join table which reference the primary table of the entity owning the association. In other words, the PK of the parent table which owns the relationship.  
- schema: the schema of the table.  
- uniqueConstraints: unique constraints that are to be placed on the table.  
  
Before defining the relationship we need to think of which side will be the parent of the relationship, which will be the one to have all the configuration of the relationship. However, since a many-to-many relationship is achieved by using an intermediary table, there will be no owner side in the database. For instance, between Book and Author, Author will be the parent because we could have an Author without Book, but a Book needs an Author. In case of the relationship between Student and Course, the parent entity would be Student since when the student enrolls the course is when the relationship is created.  
  
There are two ways of mapping this relationship: unidirectional and bidirectional.  
  
1. The unidirectional relationship can be achieved by using the @ManyToMany annotation just in one entity in conjunction with the @JoinTable annotation to define the properties of the intermediary table. In our example:  
  
```java
Student.java
//Many-to-Many relationship
@ManyToMany(fetch = FetchType.EAGER)
@JoinTable(name="course_student", joinColumns=@JoinColumn(name="student"), inverseJoinColumns=@JoinColumn(name="course"))
private List<Course> courses;
```
  
2. The bidirectional relationship is achieved by using the @ManyToMany annotation on the child side of the relationship just with the mappedBy property. The only difference will be in the other entity:  
  
```java
Course.java
@ManyToMany(mappedBy="courses")
private List<Student> students;
```
  
3. There is another way to implement the bidirectional relationship with more customization. Let's say that we want the students to rate the courses, information which needs to be included in the intermediary table. To do that, we need to configure the intermediary table to have more information. We have to follow the next steps to implement this solution:  
   - To create a new class annotated with @Embeddable with the information of the PK. This class can be another class or be created as an inner class inside the new entity class (in this case, the id class must be marked as static).  
   - To create the entity of the intermediary table using the PK created in the previous step.  
   - To mark as @ManyToOne and @MapsId the relationship between the FK of the previous step with the PK in the main table.  
   - To mark as @OneToMany the relationship in the main tables and to modify the type of the collection to the new class created previously.  
  
If the relationship in the parent entity is marked as CascadeType.ALL, in this case student, when it is saved into the database it'll try to save the intermediary entity as well. However, since the intermediary entity has a composed id which consists of the id of the student and the id of the course, it must be saved before the student and the course, so in order to prevent collision due to the cascade operation when the student is save, the cascade type must be removed or set to MERGE.  
  
```java
@Getter
@Setter
@EqualsAndHashCode
@Embeddable
public class StudentCourseId implements Serializable {
    @Column(name = "student")
    Long student;
    @Column(name = "course")
    Long course;
    public StudentCourseId() {}
    public StudentCourseId(Long student, Long course) {
        this.student = student;
        this.course = course;
    }
}

@Data
@Entity
public class StudentCourseRating {
    @EmbeddedId
    StudentCourseId id;
    @ManyToOne
    @MapsId("studentId")
    @JoinColumn(name = "student")
    Student student;
    @ManyToOne
    @MapsId("courseId")
    @JoinColumn(name = "course")
    Course course;
    int rating;
}`  

Course.java
@OneToMany(targetEntity = StudentCourseRating.class, mappedBy="course")
private List<StudentCourseRating> ratings;

Student.java
@OneToMany(cascade = CascadeType.MERGE, targetEntity = StudentCourseRating.class, mappedBy = "student")
private List<StudentCourseRating> ratings;
```
  
4. There is one more way of developing this relationship, which is by using another entity totally different. In this approach, the new entity would be mapped as any other entity (with its own id), the student and the course attributes would be marked as @ManyToOne and the Student and Course entity would have a @OneToMany relationship to this new class. This could be useful if the key pair student-course is gonna be present more than once (for instance, the student could enroll the course more than once because he/she didn't pass the course in the first attempt).  
  
```java
@Entity
@Data
class CourseRegistration {
    @Id
    @GeneratedValue(strategy = GenerationType.AUTO)
    Long id;
    @ManyToOne
    @JoinColumn(name = "student")
    Student student;
    @ManyToOne
    @JoinColumn(name = "course")
    Course course;
    @Column
    LocalDateTime registeredAt;
    @Column
    int grade;
}`  
  
Course.java
@OneToMany(targetEntity = CourseRegistration.class, mappedBy="course")
private List<CourseRegistration> students;
  
Student.java
@OneToMany(targetEntity = CourseRegistration.class, mappedBy = "student")
private List<CourseRegistration> courses;
```
  
As always, the @ManyToOne and @OneToMany operations can be configured to define the behavior of the cascade operations and the fetch mode.  
  
# Transactions  
A database transaction symbolizes a unit of work performed within a database management system (or similar system) against a database, and treated in a coherent and reliable way independent of other transactions. A transaction generally represents any change in a database. Transactions in a database environment have two main purposes:  
1. To provide reliable units of work that allow correct recovery from failures and keep a database consistent even in cases of system failure, when execution stops (completely or partially) and many operations upon a database remain uncompleted, with unclear status.  
2. To provide isolation between programs accessing a database concurrently. If this isolation is not provided, the programs' outcomes are possibly erroneous.  
  
## Transactions with Spring and JPA  
Spring 3.1 introduces the @EnableTransactionManagement annotation that we can use in a @Configuration class to enable transactional support. However, if we're using a Spring Boot project and have a spring-data-* or spring-tx dependencies on the classpath, then transaction management will be enabled by default.  
  
With transactions configured, we can now annotate a bean with @Transactional either at the class or method level. The annotation supports further configuration as well:  
- The Propagation Type of the transaction.  
- The Isolation Level of the transaction.  
- A timeout for the operation wrapped by the transaction.  
- A readOnly flag – a hint for the persistence provider that the transaction should be read only.  
- The Rollback rules for the transaction.  
  
By default, rollback happens for runtime, unchecked exceptions only. The checked exception does not trigger a rollback of the transaction. We can, of course, configure this behavior with the rollbackFor and noRollbackFor annotation parameters.  
  
At a high level, Spring creates proxies for all the classes annotated with @Transactional, either on the class or on any of the methods. The proxy allows the framework to inject transactional logic before and after the running method, mainly for starting and committing the transaction. What's important to keep in mind is that, if the transactional bean is implementing an interface, by default the proxy will be a Java Dynamic Proxy. This means that only external method calls that come in through the proxy will be intercepted. Any self-invocation calls will not start any transaction, even if the method has the @Transactional annotation.  
  
The JTA (Java Transactional API) @Transactional annotation has the following properties:  
- `rollbackOn`: list of exception classes where we want rollback to be applied.  
- `dontRollbackOn`: list of exception classes where we don't want rollback to be applied.  
- `TxType`: type of transaction created. Possible values:  
  - REQUIRED: If the client is running within a transaction and invokes the bean’s method, the method executes within the client’s transaction. If the client is not associated with a transaction, the container starts a new transaction before running the method. Default value.  
  - REQUIRES_NEW: If the client is running within a transaction and invokes the bean’s method, the container takes the following steps:  
    1. Suspends the client’s transaction  
    2. Starts a new transaction  
    3. Delegates the call to the method  
    4. Resumes the client’s transaction after the method completes  
    - If the client is not associated with a transaction, the container starts a new transaction before running the method. We should use the RequiresNew attribute when we want to ensure that the method always runs within a new transaction.  
  - MANDATORY:  if the client is running within a transaction and invokes the bean’s method, the method executes within the client’s transaction. If the client is not associated with a transaction, the container throws the TransactionRequiredException. Use the Mandatory attribute if the enterprise bean’s method must use the transaction of the client.  
  - SUPPORTS: If the client is running within a transaction and invokes the bean’s method, the method executes within the client’s transaction. If the client is not associated with a transaction, the container does not start a new transaction before running the method. Because the transactional behavior of the method may vary, you should use the Supports attribute with caution.  
  - NOT_SUPPORTED: if the client is running within a transaction and invokes the bean’s method, the container suspends the client’s transaction before invoking the method. After the method has completed, the container resumes the client’s transaction. If the client is not associated with a transaction, the container does not start a new transaction before running the method. Use the NotSupported attribute for methods that don’t need transactions. Because transactions involve overhead, this attribute may improve performance.  
  - NEVER: If the client is running within a transaction and invokes the enterprise bean’s method, the container throws a RemoteException. If the client is not associated with a transaction, the container does not start a new transaction before running the method.  
  
The Spring @Transactional annotation has the following properties among others:  
- `isolation`: not available in JTA, it offers transaction-scoped isolation. The isolation property defines how much a transaction can be impacted by other concurrent transactions. Another way to see it is how selfish a transaction is with regards to data. In an ideal situation, all transactions should be isolated each other. However, this may impact the performance because it implies to block rows in a database. This aggressive strategy may make the concurrency difficult, stopping some transactions waiting for the other ones to be concluded. Concurrency is necessary to have a good performance. However, while necessary, can lead to the following scenarios if it is not managed properly:  
  - Dirty reads: they happen when a data is read after it has been modified but before it has been committed. The data is not up to date, is dirty.  
  - Non-repeatable read: they occur, when during the course of a transaction, a row is retrieved twice and the values within the row differ between reads. This usually happens because there is other transaction working with the data.  
  - Ghost read: they are similar to non-repeatable read. In this scenario, there is a transaction reading several rows several times and there is another transaction which inserts some records between those rows, so the first transaction will retrieve more data in the subsequent reads than in the first one, data which was not there before.  
  - The values offered by Spring are:  
    - DEFAULT: it uses the isolation level provided by the database.  
    - READ_COMMITTED: it allows to read from concurrent transactions which have been committed. Dirty reads are prevented, but non-repeatable and ghost read can happen.  
    - READ_UNCOMMITTED: it allows to read uncommitted changes. It may lead to dirty, non-repeatable and ghost read   
    - REPEATABLE_READ: multiple accesses to the same field will return the same result unless it gets changed by another transaction. Dirty reads and non-repeatable reads are avoided. Ghost read may still happen.  
    - SERIALIZABLE: maximum level of isolation. There is no dirty, non-repeatable and ghost read. However, it is the worst in terms of performance because the rows will get blocked until the transaction is finished.  
- `noRollbackFor`: defines zero (0) or more exception Classes, which must be subclasses of Throwable, indicating which exception types must not cause a transaction rollback.  
- `noRollbackForClassName`: defines zero (0) or more exception names (for exceptions which must be a subclass of Throwable) indicating which exception types must not cause a transaction rollback.  
- `propagation`: equivalent to JTA transaction type. The values are:  
  - REQUIRED: default value, same as JTA REQUIRED. In plain words, my method needs a transaction, either open one for me or use an existing one → getConnection(). setAutocommit(false). commit().  
  - SUPPORTS: same as JTA SUPPORTS. In plain words, I don’t really care if a transaction is open or not, I can work either way → nothing to do with JDBC.  
  - MANDATORY: same as JTA MANDATORY. In plain words, I’m not going to open up a transaction myself, but I’m going to cry if no one else opened one up → nothing to do with JDBC  
  - REQUIRE_NEW: same as JTA REQUIRES_NEW. In plain words, I want my completely own transaction → getConnection(). setAutocommit(false). commit(). The current transaction (if exists) will be stopped and then resumed.  
  - NOT_SUPPORTED: same as JTA NOT_SUPPORTED. In plain words, I really don’t like transactions, I will even try and suspend a current, running transaction → nothing to do with JDBC  
  - NEVER: same as JTA NEVER. In plain words, I’m going to cry if someone else started up a transaction → nothing to do with JDBC  
  - NESTED: the method should be running within a nested transaction if there is a transaction running.   
  - `readOnly`: a boolean flag that can be set to true if the transaction is effectively read-only, allowing for corresponding optimizations at runtime.  
- `rollbackFor`: defines zero (0) or more exception classes, which must be subclasses of Throwable, indicating which exception types must cause a transaction rollback.  
- `rollbackForClassName`: defines zero (0) or more exception names (for exceptions which must be a subclass of Throwable), indicating which exception types must cause a transaction rollback.  
- `timeout`: the timeout for this transaction (in seconds).  
  
JTA Transactional annotation applies to CDI-managed beans and classes defined as managed beans by the Java EE specification, whereas Spring's Transactional annotation applies only to Spring beans.  
  
It's also worth noting that support for JTA 1.2 was introduced in Spring Framework 4.0. Thus, we can use the JTA Transactional annotation in Spring applications. However, the other way around is not possible since we can't use Spring annotations outside the Spring context.  
  
# Spring Data JPA Features  
## Repositories  
Spring Data makes really easy to create a repository for a new entity. There is no need of boilerplate code, we just need to create a new interface and to extend some of the interfaces Spring Data provides to have a functional repository ready to use. The interfaces Spring Data provides (and its methods) are:  
 - `JpaRepository<T, ID>`: it is mandatory to define the entity type (T) and the id type (ID). Extends from PagingAndSortingRepository and QueryByExampleExecutor. The methods provided by this interface are:  
   - `List<T> findAll()`: get all records for this particular entity from the database. The behavior of the linked entities will depend on the fetch type configured.  
   - `List<T> findAll(Sort var1)`: same as above, but with a specific order defined by var1.  
   - `<S extends T> List<S> saveAll(Iterable<S> var1)`: save all the entities within the var1 parameter.  
   - `void flush()`: flushes all pending changes to the database.  
   - `<S extends T> S saveAndFlush(S var1)`: saves an entity and flushes changes instantly.  
   - `void deleteInBatch(Iterable<T> var1)`: deletes the given entities in a batch which means it will create a single Query.  
   - `void deleteAllInBatch()`: deletes all entities in a batch call.  
   - `T getOne(ID var1)`: returns a reference to the entity with the given identifier. Depending on how the JPA persistence provider is implemented this is very likely to always return an instance and throw an EntityNotFoundException on first access. Some of them will reject invalid identifiers immediately.  
   - `<S extends T> List<S> findAll(Example<S> var1)`: same as findAll, but with a criteria defined by the Example var1 sent as parameter.  
   - `<S extends T> List<S> findAll(Example<S> var1, Sort var2)`: same as above, but with a specified order.  
 - `PagingAndSortingRepository`: extends from CrudRepository. The methods provided by this interface are:  
   - `Iterable<T> findAll(Sort var1)`: returns all entities sorted by the given options.  
   - `Page<T> findAll(Pageable var1)`: returns a Page of entities meeting the paging restriction provided in the Pageable object.  
 - `CrudRepository`: extends from Repository. The methods provided by this interface are:  
   - `<S extends T> S save(S var1)`: saves a given entity. Use the returned instance for further operations as the save operation might have changed the entity instance completely.  
   - `<S extends T> Iterable<S> saveAll(Iterable<S> var1)`: saves all given entities.  
   - `Optional<T> findById(ID var1)`: retrieves an entity (if exists) by its id.  
   - `boolean existsById(ID var1)`: returns whether an entity with the given id exists.  
   - `Iterable<T> findAll()`: returns all instances of the type.  
   - `Iterable<T> findAllById(Iterable<ID> var1)`: returns all instances of the type T with the given IDs. If some or all ids are not found, no entities are returned for these IDs. The order of elements in the result is not guaranteed.  
   - `long count()`: returns the number of entities available.  
   - `void deleteById(ID var1)`: deletes the entity with the given id.  
   - `void delete(T var1)`: deletes a given entity.  
   - `void deleteAll(Iterable<? extends T> var1)`: deletes the given entities.  
   - `void deleteAll()`: deletes all entities managed by the repository.  
 - `QueryByExampleExecutor`: The methods provided by this interface are:  
   - `<S extends T> Optional<S> findOne(Example<S> var1)`: returns a single entity matching the given Example or null if none was found.  
   - `<S extends T> Iterable<S> findAll(Example<S> var1)`: returns all entities matching the given Example. In case no match could be found an empty Iterable is returned.  
   - `<S extends T> Iterable<S> findAll(Example<S> var1, Sort var2)`: returns all entities matching the given Example applying the given Sort. In case no match could be found an empty Iterable is returned.  
   - `<S extends T> Page<S> findAll(Example<S> var1, Pageable var2)`: returns a Page of entities matching the given Example. In case no match could be found, an empty Page is returned.  
   - `<S extends T> long count(Example<S> var1)`: returns the number of instances matching the given Example.  
   - `<S extends T> boolean exists(Example<S> var1)`: checks whether the data store contains elements that match the given Example.  
 - `Repository`: base interface.  
  
## Query methods  
  
Standard CRUD functionality repositories usually have queries on the underlying datastore. With Spring Data, declaring those queries becomes a four-step process:  
1. Declare an interface extending one of the interfaces previously explained.  
2. Declare query methods on the interface by using Spring naming convention.  
3. Set up Spring to create proxy instances for those interfaces, either with JavaConfig or with XML configuration.  
4. Inject the repository instance and use it.  
  
The question is, how can we define methods just by declaring them in the interface? That is done by the repository proxy, which derives the query from the method name. It has to ways to do it:  
1. By deriving the query from the method name directly.  
2. By using a manually defined query.  
  
In this section we're gonna be covering the strategy followed to define the queries in the repository. Derived method names have two main parts separated by the first By keyword (for instance findByFirstName), where camel case is used:  
1. The first part is the introducer, and it tells Spring what to do. Spring Data JPA supports `find`, `read`, `query`, `count` and `get`. In the previous example, we used find.  
2. The second part is the criteria, and it contains the entity-specific condition expressions of the query. In the previous example, we used FirstName.  
  
Spring offers the following criterias:  
- `Distinct`. For instance, `findDistinctByLastnameAndFirstname`, which is equivalent to the SQL query `select distinct …​ where x.lastname = ?1 and x.firstname = ?2`.  
- `And`. For instance, `findByLastnameAndFirstname`, which is equivalent to the SQL query `... where x.lastname = ?1 and x.firstname = ?2`.  
- `Or`. For instance, `findByLastnameOrFirstname`, which is equivalent to the SQL query `… where x.lastname = ?1 or x.firstname = ?2`.  
- `Is, Equals`. For instance, `findByFirstname, findByFirstnameIs, findByFirstnameEquals`, which are equivalent to the SQL query `… where x.firstname = ?1`.  
- `Between`. For instance, `findByStartDateBetween`, which is equivalent to the SQL query `… where x.startDate between ?1 and ?2`.  
- `LessThan`. For instance, `findByAgeLessThan`, which is equivalent to the SQL query `… where x.age < ?1`.  
- `LessThanEqual`. For instance, `findByAgeLessThanEqual`, which is equivalent to the SQL query ` … where x.age <= ?1`.  
- `GreaterThan`. For instance, `findByAgeGreaterThan`, which is equivalent to the SQL query ` … where x.age > ?1`.  
- `GreaterThanEqual`. For instance, `findByAgeGreaterThanEqual`, which is equivalent to the SQL query ` … where x.age >= ?1`.  
- `After`. For instance, `findByStartDateAfter`, which is equivalent to the SQL query ` … where x.startDate > ?1`.  
- `Before`. For instance, `findByStartDateBefore`, which is equivalent to the SQL query ` … where x.startDate < ?1`.  
- `IsNull, Null`. For instance, `findByAge(Is)Null`, which is equivalent to the SQL query ` … where x.age is null`.  
- `IsNotNull, NotNull`. For instance, `findByAge(Is)NotNull`, which is equivalent to the SQL query ` … where x.age not null`.  
- `Like`. For instance, `findByFirstnameLike`, which is equivalent to the SQL query ` … where x.firstname like ?1`. We can use the character '%' like we do in SQL as part of regular expression.  
- `NotLike`. For instance, `findByFirstnameNotLike`, which is equivalent to the SQL query ` … where x.firstname not like ?1`. We can use the character '%' like we do in SQL as part of regular expression.  
- `StartsWith, StartingWith, IsStartingWith`. For instance, `findByFirstnameStartsWith, findByFirstnameStartingWith, findByFirstnameIsStartingWith`, which is equivalent to the SQL query ` … where x.firstname like ?1` (parameter bound with appended %).  
- `EndsWith, EndingWith, IsEndingWith`. For instance, `findByFirstnameEndsWith, findByFirstnameEndingWith, findByFirstnameIsEndingWith`, which is equivalent to the SQL query ` … where x.firstname like ?1` (parameter bound with prepended %).  
- `Containing, IsContaining`. For instance, `findByFirstnameContaining, findByFirstnameIsContaining`, which is equivalent to the SQL query ` … where x.firstname like ?1` (parameter bound wrapped in %).  
- `OrderBy`. For instance, `findByAgeOrderByLastnameDesc`, which is equivalent to the SQL query ` … where x.age = ?1 order by x.lastname desc`.  
- `Not`. For instance, `findByLastnameNot`, which is equivalent to the SQL query ` … where x.lastname <> ?1`.  
- `In`. For instance, `findByAgeIn(Collection<Age> ages)`, which is equivalent to the SQL query ` … where x.age in ?1`.  
- `NotIn`. For instance, `findByAgeNotIn(Collection<Age> ages)`, which is equivalent to the SQL query ` … where x.age not in ?1`.  
- `True`. For instance, `findByActiveTrue()`, which is equivalent to the SQL query ` … where x.active = true`.  
- `False`. For instance, `findByActiveFalse()`, which is equivalent to the SQL query ` … where x.active = false`.  
- `IgnoreCase`. For instance, `findByFirstnameIgnoreCase`, which is equivalent to the SQL query ` … where UPPER(x.firstname) = UPPER(?1)`.  
  
When defining the property expressions, although this should work for most cases, it is possible for the algorithm to select the wrong property. To resolve this ambiguity you can use _ inside your method name to manually define traversal points. For instance, with the method `List<Person> findByAddress_ZipCode(ZipCode zipCode)` we're telling Spring specifically to find the the property 1 address, and the property 2 zipCode.  
  
### Special types to enhance the functionality of the queries  
  
Besides the parameters defined so far, Sprint recognizes certain specific types:  
- `Optional`. For instance, `Optional<User> findOptionalByEmailAddress(EmailAddress emailAddress)`.  
- `Pageable`. For instance, `Page<User> findByLastname(String lastname, Pageable pageable)` or `List<User> findByLastname(String lastname, Pageable pageable)`.  
- `Slice`. For instance, `Slice<User> findByLastname(String lastname, Pageable pageable)`.  
- `Sort`. For instance, `List<User> findByLastname(String lastname, Sort sort)`. We can set the direction of the order with `Asc` and `Desc`, for instance, `findByOrderByAgeDesc` or `findByOrderByAgeDesc`.  
- Limiting query results. We can limit the results of a query by using different expressions:  
  - `First`. It returns only 1 element. For instance, `findFirstByOrderByLastnameAsc`. We can add a number to get more than the first element only. For instance, `queryFirst10ByLastname`.  
  - `Top`. It returns only 1 element. For instance, `findTopByOrderByLastnameAsc`. We can add a number to get more than the first element only. For instance, `findTop3ByLastname`.  
  
Query methods that return multiple results can use standard Java `Iterable`, `List` and `Set`. Beyond that, Spring supports returning Spring Data’s Streamable, a custom extension of Iterable, or the Java 8 `Stream`, where data store-specific methods are used to perform the streaming. It provides convenience methods to access a non-parallel Stream (missing from Iterable) and the ability to directly filter and map over the elements and concatenate the Streamable to others. Let's see the following example:  
  
```java
interface PersonRepository extends Repository<Person, Long> {
   Streamable<Person> findByFirstnameContaining(String firstname);
   Streamable<Person> findByLastnameContaining(String lastname);
   Stream<Person> readAllByFirstnameNotNull();
}
Streamable<Person> result = repository.findByFirstnameContaining("av").and(repository.findByLastnameContaining("ea"));
```
  
APIs taking Sort and Pageable expect non-null values to be handed into methods. If you do not want to apply any sorting or pagination, use Sort.unsorted() and Pageable.unpaged().  
  
### Null Handling of Repository Methods  
  
Spring provides a tooling-friendly approach and opt-in null checks during runtime, as follows:  
- `@NonNullApi`: used on the package level to declare that the default behavior for parameters and return values is, respectively, neither to accept nor to produce null values.  
- `@NonNull`: used on a parameter or return value that must not be null (not needed on a parameter and return value where @NonNullApi applies).  
- `@Nullable`: used on a parameter or return value that can be null.  
  
Let's see the following example:  

```java
interface UserRepository extends Repository<User, Long> {  
  User getByEmailAddress(EmailAddress emailAddress);
  @Nullable
  User findByEmailAddress(@Nullable EmailAddress emailAdress);
  Optional<User> findOptionalByEmailAddress(EmailAddress emailAddress);
}  
```
  
The query getByEmailAddress:  
- Throws an `EmptyResultDataAccessException` when the query does not produce a result.  
- Throws an `IllegalArgumentException` when the emailAddress handed to the method is null.  
  
The query findByEmailAddress:  
- Returns `null` when the query does not produce a result.  
- Also accepts `null` as the value for emailAddress.  
  
The query findOptionalByEmailAddress:  
- Returns `Optional.empty()` when the query does not produce a result.  
- Throws an `IllegalArgumentException` when the `emailAddress` handed to the method is `null`.  
  
### Asynchronous Query Results  
We can run repository queries asynchronously by using Spring’s asynchronous method running capability with the help of the annotation `@Async`. This means the method returns immediately upon invocation while the actual query occurs in a task that has been submitted to a Spring TaskExecutor. Asynchronous queries differ from reactive queries and should not be mixed.  

```java
@Async
Future<User> findByFirstname(String firstname);
//Use java.util.concurrent.Future as the return type`  
@Async
CompletableFuture<User> findOneByFirstname(String firstname);
//Use a Java 8 java.util.concurrent.CompletableFuture as the return type
@Async
ListenableFuture<User> findOneByLastname(String lastname);
//Use a org.springframework.util.concurrent.ListenableFuture as the return type
```
  
### @Query  
The behavior of the methods created by naming convention can be personalized by using the `@Query` annotation. This annotation can be used to execute both JPQL and native SQL queries. This annotation takes precedence over named queries, which are annotated with @NamedQuery. By default, the query definition uses JPQL. Let's see a simple example:  

```java
@Query("SELECT u FROM User u WHERE u.status = ?1 and u.name = ?2")
User findUserByStatusAndName(Integer status, String name);
  
@Query(value = "SELECT u FROM User u WHERE u.name IN :names")
List<User> findUserByNameList(@Param("names") Collection<String> names);
```
  
We can do the same with named parameters instead of referencing the location of the parameter:  

```java
@Query("SELECT u FROM User u WHERE u.status = :status and u.name = :name")
User findUserByStatusAndName(@Param("status") Integer status, @Param("name") String name);
```
  
We can use also native SQL to define our query. All we have to do is set the value of the nativeQuery attribute to true and define the native SQL query in the value attribute of the annotation. However, if we do that, we lose the independency with the database technology. Let's see another simple example:  

```java
@Query(value = "SELECT * FROM Users u WHERE u.status = ?1 and u.name = ?2", nativeQuery = true)
User findUserByStatusAndNameNamedParamsNative(Integer status, String name);
```
  
The same with named parameters:  

```java
@Query(value = "SELECT * FROM Users u WHERE u.status = :status and u.name = :name", nativeQuery = true)
User findUserByStatusAndNameNamedParamsNative( @Param("status") Integer status, @Param("name") String name),
```
  
We can define the order as a parameter of the query:  

```java
`@Query(value = "SELECT u FROM User u")
`List<User> findAllUsers(Sort sort);
```
  
The previous example can be used for instance with these two calls:  
- `userRepository.findAllUsers(Sort.by("name"))`  
- `userRepository.findAllUsers(JpaSort.unsafe("LENGTH(name)"))`. JpaSort.unsafe is used because we're sorting by a property which is not present in the model, which is the length of the property name.  
  
@Query can be used not only to retrieve information, but to run save/update operations into the database. For this, we use the @Modifying annotation. Let's see a few examples both in JPQL and in native SQL.  

```java
@Modifying
@Query("update User u set u.status = :status where u.name = :name")
int updateUserSetStatusForName(@Param("status") Integer status, @Param("name") String name);
  
@Modifying
@Query(value = "update Users u set u.status = ? where u.name = ?", nativeQuery = true)
int updateUserSetStatusForNameNative(Integer status, String name);
  
@Modifying
@Query( value = "insert into Users (name, age, email, status) values (:name, :age, :email, :status)", nativeQuery = true)
void insertUser(@Param("name") String name, @Param("age") Integer age, @Param("status") Integer status, @Param("email") String email);
```
  
### @NamedQuery  
`@NamedQuery` annotation is a predefined query that we create and associate with a container-managed entity. While @NamedQuery is used on domain classes, Spring Data JPA @Query annotation is used on Repository interface. This frees the domain classes from persistence specific information, which is a good thing.  
  
The queries are defined at entity level, and they just need to be declared in the interface repository to be used by any other component. We can define as many queries as needed either separately or inside the @NamedQueries annotation. We can define both JPQL and native named queries. Let's see this example:  

```java
@Entity
@NamedQuery(name = "Author.findByFirstName", query = "FROM Author WHERE firstName = ?1")
@NamedQuery(name = "Author.findByFirstNameAndLastName", query = "SELECT a FROM Author a WHERE a.firstName = ?1 AND a.lastName = ?2")
@NamedNativeQuery(name = "Author.findByFirstNameNative", query = "SELECT * FROM author WHERE first_name = ?", resultClass = Author.class)
@NamedNativeQuery(name = "Author.findByFirstNameAndLastNameNative", query = "SELECT * FROM author WHERE first_name = ? AND last_name = ?", resultClass = Author.class)
public class Author { ... }
```
  
We can execute the query (or queries both by using JPA’s EntityManager (see custom repository section) and Spring Data Repository.  
  
Using JPA’s EntityManager, we can run named native and named JPQL queries in the same way:  
- We call the createNamedQuery method on the EntityManager with the name of the named query we want to execute. That gives you an instance of a Query or TypedQuery interface.  
- We then call the setParameter method on the returned interface for each bind parameter used in your query.  
- As a final step, we call the getSingleResult or getResultSet method on the Query or TypedQuery interface. That executes the query and returns 1 or multiple result set records. Let's see an example:  

```java
Query q = em.createNamedQuery("Author.findByFirstName");
q.setParameter(1, "Thorben");
List a = q.getResultList();
```
  
To use the named query inside a Sprint Data Repository, the only thing we need to do is to declare the method in the interface. For instance:  

```java
public interface AuthorRepository extends JpaRepository<Author, Long> {
    List<Author> findByFirstName(String firstName);
    List<Author> findByFirstNameAndLastName(String firstName, String lastName);
}
```
  
## Custom repository  
If we need more flexibility than we're offered by Spring Data and its amazing capabilities, we can always create our own custom repository to define the body of the methods we need. We can follow the next steps to create both a Spring Data Repository and a custom repository so we've got access to both when we work with the repository object:  
1. To create a new custom repository interface. This interface won't extend any Spring Data interface, it'll just contain the methods for our custom repository.  
2. To create the Spring Data Repository interface. This repository will extend both Sprint Data interface and our custom interface.  
3. To create the class to implement the methods of our custom interface.  

```java
public interface UserRepositoryCustom {...}
public interface UserRepository extends JpaRepository<User, Long>, UserRepositoryCustom {...}
public class UserRepositoryCustomImpl implements UserRepositoryCustom {...}
```
  
Now we have the structure, we need to implement the methods. In order to do that, we need access to the database layer. That access will be provided by the entity manager.  

```java
public class UserRepositoryCustomImpl implements UserRepositoryCustom {
@Autowired
private EntityManager entityManager;
public void someCustomMethod(User user) {
...
}
}
```

In order for Spring to locate the custom repository, we need to tell it how to recognize them. In this case, we're using the postfix CustomImpl (this is not needed in Sprint Boot):  

```java
@EnableJpaRepositories(basePackages = "...", repositoryImplementationPostfix = "CustomImpl")
```
  
## QueryDSL  
As we know, object-relational mapping frameworks are at the core of Enterprise Java. These compensate the mismatch between object-oriented approach and relational database model. They also allow developers to write cleaner and more concise persistence code and domain logic. However, one of the most difficult design choices for an ORM framework is the API for building correct and type-safe queries.   
  
One of the most widely used Java ORM frameworks, Hibernate (and also closely related JPA standard), proposes a string-based query language HQL (JPQL) very similar to SQL. The JPA 2.0 standard brought an improvement in the form of Criteria Query API. However, Criteria Query API ended up very verbose and practically unreadable. Querydsl library soon emerged, based on the same idea of generated metadata classes, yet implemented with a fluent and readable API.  
  
Before using QueryDSL, we need to configure our project to generate the classes needed.   

```xml
<dependencies>
        <dependency>
            <groupId>com.querydsl</groupId>
            <artifactId>querydsl-jpa</artifactId>
        </dependency>
        <dependency>
            <groupId>com.querydsl</groupId>
            <artifactId>querydsl-apt</artifactId>
        </dependency>
</dependencies>
<build>
        <plugins>
            <plugin>
                <groupId>com.mysema.maven</groupId>
                <artifactId>apt-maven-plugin</artifactId>
                <version>1.1.3</version>
                <executions>
                    <execution>
                        <phase>generate-sources</phase>
                        <goals>
                            <goal>process</goal>
                        </goals>
                        <configuration>
                            <outputDirectory>${project.basedir}/target/generated-sources/java</outputDirectory>                           <processor>com.querydsl.apt.jpa.JPAAnnotationProcessor</processor>`  
                        </configuration>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
```

This tool generates the so called Q-types - classes that are directly related to the entity classes of our application, but are prefixed with letter Q. For instance, if we have a User class marked with the @Entity annotation in our application, then the generated Q-type will reside in a QUser.java source file. We just need to run the package goal from maven to generate the files.  

To build a query, first we need both the Q-type class and an instance of a JPAQueryFactory, which is a preferred way of starting the building process. The only thing that JPAQueryFactory needs is an EntityManager, which is already available in the custom repository created above.  

```java
public static final QUser user = new QUser("user");
JPAQueryFactory queryFactory = new JPAQueryFactory(em);
```

Now we have everything we need, let's see several examples of how to use QueryDSL.  

### Querying data  

```java
User c = queryFactory.selectFrom(user).where(user.login.eq("David")).fetchOne();
```

### Ordering and Grouping  

```java
List<User> c = queryFactory.selectFrom(user).orderBy(user.login.asc()).fetch();
``` 
  
Suppose we need to group all posts by title and count duplicating titles. This is done with the .groupBy() clause. We’ll also want to order the titles by resulting occurrence count.  

```java
NumberPath<Long> count = Expressions.numberPath(Long.class, "c");
List<Tuple> userTitleCounts = queryFactory.select(blogPost.title, blogPost.id.count().as(count)).from(blogPost).groupBy(blogPost.title).orderBy(count.desc()).fetch();
``` 
  
### Complex Queries With Joins and Subqueries  
Let’s find all users that wrote a post titled “Hello World!” For such query we could use an inner join. Notice we’ve created an alias blogPost for the joined table to reference it in the .on() clause:  

```java
QBlogPost blogPost = QBlogPost.blogPost;
List<User> users = queryFactory.selectFrom(user).innerJoin(user.blogPosts, blogPost).on(blogPost.title.eq("Hello World!")).fetch();
``` 
  
Now let’s try to achieve the same with subquery:  

```java
List<User> users = queryFactory.selectFrom(user).where(user.id.in(JPAExpressions.select(blogPost.user.id).from(blogPost).where(blogPost.title.eq("Hello World!")))).fetch();
``` 
  
### Modifying Data  
JPAQueryFactory allows not only constructing queries, but also modifying and deleting records. Let’s change the user's login and disable the account:  

```java
queryFactory.update(user).where(user.login.eq("Ash")).set(user.login, "Ash2").set(user.disabled, true).execute();
```
  
To delete the records matching a certain condition, we can use a similar syntax:  

```java
queryFactory.delete(user).where(user.login.eq("David")).execute();
```

## Projections
Sometimes we'll need to retrieve not the entire entity, but just some fields of it. There are several ways to achieve this with Spring Data.

### Interface-Based Projections
In this approach, what we do is to create a new interface to represent the fields we need and to use that interface in the entity repository. Let's see the following example:

```java
public interface AddressView {
    String getZipCode();
}
public interface AddressRepository extends JpaRepository<Address, Long> {
    List<AddressView> getAddressByState(String state);
}
```

### Class-Based Projections
We can create our own class projections instead of letting spring do the behind the scenes work with proxies. We don't need to create a new repository, but just to add the method we need in the repository we need (in this case Address)

```java
public class AddressDto {
    private String zipCode;
    //Constructor, getters and setters
}
public interface AddressRepository extends JpaRepository<Address, Long> {
    List<AddressDto> getAddressByState(String state);
}
```

### Dynamic Projections
An entity class may have many projections. In some cases, we may use a certain type, but in other cases, we may need another type. Sometimes, we also need to use the entity class itself. Defining separate repository interfaces or methods just to support multiple return types is cumbersome. To deal with this problem, Spring Data provides a better solution: dynamic projections. We can apply dynamic projections just by declaring a repository method with a Class parameter:

```java
public interface PersonRepository extends Repository<Person, Long> {
    // ...
    <T> T findByLastName(String lastName, Class<T> type);
}

public void myMethod() {
    Person person = personRepository.findByLastName("Doe", Person.class);
    PersonView personView = personRepository.findByLastName("Doe", PersonView.class);
    PersonDto personDto = personRepository.findByLastName("Doe", PersonDto.class);
}
```

## Auditing  
Spring provides the annotations `@CreatedBy`, `@LastModifiedBy` to capture the user who created or modified the entity as well as `@CreatedDate` and `@LastModifiedDate` to capture the point in time this happened. Let's say we want to do our Customer entity auditable. It is as easy as:  

```java
@Entity
@EntityListeners(AuditingEntityListener.class)
//Spring Data JPA entity listener
class Customer {
    @CreatedBy //User needed for this, we can get it from Sprint Security for instance
    private String user;
    @CreatedDate
    private DateTime createdDate;
    @LastModifiedBy
    private String user;
    @LastModifiedDate
    private DateTime lastModifiedDate;
}
```
  
Once the entity is configured, the only thing we need to do is to tell Spring to activate the auditing with the annotation `@EnableJpaAuditing` in conjunction with the annotation `@EnableJpaRepositories`.  
  
Another way to achieve the auditing is by using the JPA entity lifecycle events. We can use the annotations `@PrePersist`, `@PreUpdate` and `@PreRemove` to run the logic needed to update the auditing information. Let's see the following example:  

```java
@Entity
public class Customer {
    @Column(name = "operation")
    private String operation;
    @Column(name = "timestamp")
    private long timestamp;
    @PrePersist
    public void onPrePersist() { audit("INSERT"); }
    @PreUpdate
    public void onPreUpdate() { audit("UPDATE"); }
    @PreRemove
    public void onPreRemove() { audit("DELETE"); }
    private void audit(String operation) {
        setOperation(operation);
        setTimestamp((new Date()).getTime());
    }
}
```
  
If we need to add such auditing to multiple classes, we can use `@EntityListeners` to centralize the code. For example:  

```java
@EntityListeners(AuditListener.class)
@Entity
public class Customer { ... }

public class AuditListener {
    @PrePersist
    @PreUpdate
    @PreRemove
    private void beforeAnyOperation(Object object) { ... }
}
```
  
## Multiple Spring Data Modules  
  
Using a unique Spring Data module in our application makes things simple, because all repository interfaces in the defined scope are bound to the Spring Data module. Sometimes, applications require using more than one Spring Data module. In such cases, a repository definition must distinguish between persistence technologies. When it detects multiple repository factories on the class path, Spring Data enters strict repository configuration mode. Strict configuration uses details on the repository or the domain class to decide about Spring Data module binding for a repository definition:  
1. If the repository definition extends the module-specific repository, it is a valid candidate for the particular Spring Data module.  
2. If the domain class is annotated with the module-specific type annotation, it is a valid candidate for the particular Spring Data module. Spring Data modules accept either third-party annotations (such as JPA’s @Entity) or provide their own annotations (such as @Document for Spring Data MongoDB and Spring Data Elasticsearch).  
  
The following example shows a repository that uses module-specific interfaces (JPA in this case):  

```java
MyRepository.java
interface MyRepository extends JpaRepository<User, Long> { … }
  
MyBaseRepository.java
@NoRepositoryBean
interface MyBaseRepository<T, ID> extends JpaRepository<T, ID> { … }
  
UserRepository.java
interface UserRepository extends MyBaseRepository<User, Long> { … }
```

The annotation @NoRepositoryBean tells Sprint that that interface is not a repository, it must be ignored as repository during the scan configuration.